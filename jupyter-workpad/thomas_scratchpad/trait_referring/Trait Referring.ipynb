{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407f8cde",
   "metadata": {},
   "source": [
    "# Trait Referring Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc2f44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import referring\n",
    "\n",
    "class Args:\n",
    "    def __init__(self, trait_option='Eye', num_queries=50):\n",
    "        self.model = 'florence-2'\n",
    "        self.task_option = 'referring'\n",
    "        self.trait_option = trait_option\n",
    "        self.result_dir = './results/referring'\n",
    "        self.num_queries = num_queries\n",
    "        self.image_dir = './fish-vista/AllImages'\n",
    "        self.trait_map_path = './fish-vista/segmentation_masks/seg_id_trait_map.json'\n",
    "        self.segmentation_dir = './fish-vista/segmentation_masks/images'\n",
    "        self.dataset_csv = './fish-vista/segmentation_train.csv'\n",
    "        self.visual_output = True\n",
    "        self.debug = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1176a8f",
   "metadata": {},
   "source": [
    "### Fish Eye "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c35181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/tdeatherage3/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "  3%|▎         | 54/1707 [00:43<22:25,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average match score for Eye: 0.18\n",
      "Total rows processed: 50\n",
      "Total rows skipped: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "\n",
    "referring.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656c8cc",
   "metadata": {},
   "source": [
    "### Fish Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f914155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/tdeatherage3/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "  3%|▎         | 54/1707 [00:40<20:38,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average match score for Head: 0.04\n",
      "Total rows processed: 50\n",
      "Total rows skipped: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(trait_option=\"Head\")\n",
    "\n",
    "referring.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc164ab7",
   "metadata": {},
   "source": [
    "### Fish Dorsal Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8212a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/tdeatherage3/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "  3%|▎         | 54/1707 [00:40<20:43,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average match score for Dorsal fin: 0.0\n",
      "Total rows processed: 50\n",
      "Total rows skipped: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(trait_option=\"Dorsal fin\")\n",
    "\n",
    "referring.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e760a",
   "metadata": {},
   "source": [
    "### Fish Pecotral Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67e3eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/tdeatherage3/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "  3%|▎         | 54/1707 [00:39<20:13,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average match score for Pectoral fin: 0.0\n",
      "Total rows processed: 50\n",
      "Total rows skipped: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(trait_option=\"Pectoral fin\")\n",
    "\n",
    "referring.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc46154",
   "metadata": {},
   "source": [
    "### Fish Pelvic Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f7217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/tdeatherage3/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "  3%|▎         | 56/1707 [00:40<19:43,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average match score for Pelvic fin: 0.0\n",
      "Total rows processed: 50\n",
      "Total rows skipped: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(trait_option=\"Pelvic fin\")\n",
    "\n",
    "referring.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf1ad1",
   "metadata": {},
   "source": [
    "### Fish Anal Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb5df8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/tdeatherage3/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "  3%|▎         | 55/1707 [00:40<20:11,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average match score for Anal fin: 0.0\n",
      "Total rows processed: 50\n",
      "Total rows skipped: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(trait_option=\"Anal fin\")\n",
    "\n",
    "referring.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b217837",
   "metadata": {},
   "source": [
    "### Fish Caudal Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a178fa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/tdeatherage3/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "  3%|▎         | 54/1707 [00:40<20:38,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average match score for Caudal fin: 0.0\n",
      "Total rows processed: 50\n",
      "Total rows skipped: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(trait_option=\"Caudal fin\")\n",
    "\n",
    "referring.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5763570",
   "metadata": {},
   "source": [
    "### Fish Adipose Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6688a673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/tdeatherage3/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      " 12%|█▏        | 210/1707 [00:40<04:46,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average match score for Adipose fin: 0.0\n",
      "Total rows processed: 50\n",
      "Total rows skipped: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(trait_option=\"Adipose fin\")\n",
    "\n",
    "referring.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31537ad2",
   "metadata": {},
   "source": [
    "### Fish Barbel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e37fcc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/tdeatherage3/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      " 37%|███▋      | 625/1707 [01:32<02:39,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average match score for Barbel: 0.0\n",
      "Total rows processed: 50\n",
      "Total rows skipped: 575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(trait_option=\"Barbel\")\n",
    "\n",
    "referring.main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
