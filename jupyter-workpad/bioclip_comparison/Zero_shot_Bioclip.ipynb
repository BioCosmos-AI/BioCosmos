{"cells":[{"cell_type":"markdown","id":"14a21edb-c87a-4a91-8a4e-46d654563fa6","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"14a21edb-c87a-4a91-8a4e-46d654563fa6"},"source":["# Setup"]},{"cell_type":"code","execution_count":2,"id":"f7382586-6157-41ba-988c-d25d0ba9984b","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"f7382586-6157-41ba-988c-d25d0ba9984b","executionInfo":{"status":"ok","timestamp":1732756309871,"user_tz":300,"elapsed":3682,"user":{"displayName":"Roman Dombrovski","userId":"00001977524218258424"}},"outputId":"f97df1d5-d11d-41ea-f730-746a6fdb9701"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}],"source":["import torch\n","print(torch.cuda.is_available())  # Should return True if CUDA is correctly set up"]},{"cell_type":"code","execution_count":1,"id":"92b60d85-f80d-48ff-8dbb-a02baf9f64fd","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"92b60d85-f80d-48ff-8dbb-a02baf9f64fd","executionInfo":{"status":"ok","timestamp":1732756306190,"user_tz":300,"elapsed":24495,"user":{"displayName":"Roman Dombrovski","userId":"00001977524218258424"}},"outputId":"d84080ea-0c79-441f-abaf-3997c1e7beed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n","Collecting supervision\n","  Downloading supervision-0.25.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.11)\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n","Collecting open_clip_torch\n","  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.3.1)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n","Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.10.0.84)\n","Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (11.0.0)\n","Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.13.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n","Collecting ftfy (from open_clip_torch)\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading supervision-0.25.0-py3-none-any.whl (181 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, ftfy, fsspec, dill, multiprocess, supervision, open_clip_torch, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 ftfy-6.3.1 multiprocess-0.70.16 open_clip_torch-2.29.0 supervision-0.25.0 xxhash-3.5.0\n","Collecting git+https://github.com/deepglint/unicom.git\n","  Cloning https://github.com/deepglint/unicom.git to /tmp/pip-req-build-uwgxl46s\n","  Running command git clone --filter=blob:none --quiet https://github.com/deepglint/unicom.git /tmp/pip-req-build-uwgxl46s\n","  Resolved https://github.com/deepglint/unicom.git to commit 7407e7ce232d8fedb4e8070e1a0e381fab212ba1\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: unicom\n","  Building wheel for unicom (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unicom: filename=unicom-2.0.0-py3-none-any.whl size=289633 sha256=5c61f876ad7a754ed12d248dfce1d99bd6acf543e536d796cd9720e19a65e046\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-0obk7o1k/wheels/a1/e4/76/d9b97fbd6dcf3f6c7af0f2df181c0226c759a1686dae8b4e41\n","Successfully built unicom\n","Installing collected packages: unicom\n","Successfully installed unicom-2.0.0\n"]}],"source":["!pip install datasets transformers huggingface_hub supervision timm  sentence_transformers open_clip_torch\n","! pip install git+https://github.com/deepglint/unicom.git"]},{"cell_type":"markdown","source":["# Gather Images"],"metadata":{"id":"hU38rnf3Zhvd"},"id":"hU38rnf3Zhvd"},{"cell_type":"code","source":["!git lfs clone https://huggingface.co/datasets/sammarfy/VLM4Bio VLM4BIO_data"],"metadata":{"id":"V2qoeG9e8uy5"},"id":"V2qoeG9e8uy5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir downloaded_images\n","\n","!mv VLM4BIO_data/datasets/Bird/chunk_0/* downloaded_images\n","!mv VLM4BIO_data/datasets/Bird/chunk_1/* downloaded_images\n","!mv VLM4BIO_data/datasets/Bird/chunk_2/* downloaded_images\n","!mv VLM4BIO_data/datasets/Bird/chunk_3/* downloaded_images\n","!mv VLM4BIO_data/datasets/Bird/chunk_4/* downloaded_images\n","\n","!mv VLM4BIO_data/datasets/Butterfly/chunk_0/* downloaded_images\n","!mv VLM4BIO_data/datasets/Butterfly/chunk_1/* downloaded_images\n","!mv VLM4BIO_data/datasets/Butterfly/chunk_2/* downloaded_images\n","!mv VLM4BIO_data/datasets/Butterfly/chunk_3/* downloaded_images\n","!mv VLM4BIO_data/datasets/Butterfly/chunk_4/* downloaded_images\n","\n","!mv VLM4BIO_data/datasets/Fish/chunk_0/* downloaded_images\n","!mv VLM4BIO_data/datasets/Fish/chunk_1/* downloaded_images\n","!mv VLM4BIO_data/datasets/Fish/chunk_2/* downloaded_images\n","!mv VLM4BIO_data/datasets/Fish/chunk_3/* downloaded_images\n","!mv VLM4BIO_data/datasets/Fish/chunk_4/* downloaded_images"],"metadata":{"id":"u52aU6LJ_gQQ"},"id":"u52aU6LJ_gQQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.io import loadmat, savemat\n","import pandas as pd\n","\n","def load_df(mat_filename):\n","    \"\"\"\n","    Load dataframe for UNICOM clustering from .mat file\n","\n","    Parameters\n","    ----------\n","    mat_filename : str\n","        DESCRIPTION.\n","\n","    Returns\n","    -------\n","    df : Dataframe\n","        Dataframe of the df file including image_name, scientific_name, category, caption, image/text_embeddings fields.\n","    \"\"\"\n","\n","    data = loadmat(f\"{mat_filename}.mat\")\n","    img_embeddings = data['image_embeddings']\n","    text_embeddings = data['text_embeddings']\n","\n","    print(data['caption'].shape)\n","    # Create a DataFrame with each list as a column\n","    df = pd.DataFrame({\n","        'image_name': data['image_name'],\n","        'scientific_name': data['scientific_name'],\n","        'category': data['category'],\n","        'caption': data['caption'].squeeze(0),\n","        'image_embeddings': [sub_array for sub_array in img_embeddings],\n","        'text_embeddings': [sub_array for sub_array in text_embeddings]\n","    })\n","\n","    return df\n","embeds_df = load_df('ViT-H-14-embeddings')"],"metadata":{"id":"e90ApmGuOhYN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732756445611,"user_tz":300,"elapsed":2473,"user":{"displayName":"Roman Dombrovski","userId":"00001977524218258424"}},"outputId":"7e9f2b28-a0f2-43ce-aa93-d7cb625985dc"},"id":"e90ApmGuOhYN","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 31452)\n"]}]},{"cell_type":"code","source":["embeds_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"HxckUiqvVXmA","executionInfo":{"status":"ok","timestamp":1732756486795,"user_tz":300,"elapsed":1328,"user":{"displayName":"Roman Dombrovski","userId":"00001977524218258424"}},"outputId":"8e5776b1-c0d1-4405-bd5a-6e3090e9258d"},"id":"HxckUiqvVXmA","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              image_name  \\\n","0      UWZM-F-0001570.JPG                            ...   \n","1      UWZM-F-0001664.JPG                            ...   \n","2      UWZM-F-0001696.JPG                            ...   \n","3      UWZM-F-0001697.JPG                            ...   \n","4      UWZM-F-0000002.JPG                            ...   \n","...                                                  ...   \n","31447  Butterfly_imbalanced_test_Eueides_isabella_114...   \n","31448  Butterfly_imbalanced_test_Eueides_isabella_980...   \n","31449  Butterfly_imbalanced_test_Rhetus_periander_307...   \n","31450  Butterfly_imbalanced_test_Rhetus_periander_371...   \n","31451  Butterfly_imbalanced_test_Rhetus_periander_372...   \n","\n","                            scientific_name   category  \\\n","0      Lepomis macrochirus                   Fish        \n","1      Lepomis megalotis                     Fish        \n","2      Lepomis microlophus                   Fish        \n","3      Lepomis punctatus                     Fish        \n","4      Alosa aestivalis                      Fish        \n","...                                     ...        ...   \n","31447  Eueides isabella                      Butterfly   \n","31448  Eueides isabella                      Butterfly   \n","31449  Rhetus periander                      Butterfly   \n","31450  Rhetus periander                      Butterfly   \n","31451  Rhetus periander                      Butterfly   \n","\n","                                                 caption  \\\n","0      [This image depicts a Lepomis macrochirus, a s...   \n","1      [This image depicts a Lepomis megalotis, showc...   \n","2      [This image depicts a Lepomis microlophus, a s...   \n","3      [This image depicts a Lepomis punctatus, a sma...   \n","4      [The image shows a specimen of Alosa aestivali...   \n","...                                                  ...   \n","31447  [The image shows a close-up of Eueides isabell...   \n","31448  [This image shows a close-up of Eueides isabel...   \n","31449  [The image shows a close-up view of a Rhetus p...   \n","31450  [The image shows a close-up of a Rhetus perian...   \n","31451  [The image shows a close-up of Rhetus periande...   \n","\n","                                        image_embeddings  \\\n","0      [[0.0062551806, 0.016257662, -0.051555164, -0....   \n","1      [[-0.010808857, 0.010653244, -0.039921395, 0.0...   \n","2      [[-0.008302152, 0.016121196, -0.037911564, 0.0...   \n","3      [[0.005701786, 0.018549936, -0.05157007, 0.001...   \n","4      [[-0.008683015, 0.0030286494, -0.040459294, 0....   \n","...                                                  ...   \n","31447  [[0.035732385, -0.020132823, -0.017447814, 0.0...   \n","31448  [[0.044416793, -0.034998138, -0.016503036, 0.0...   \n","31449  [[0.052031703, -0.01843505, -0.0047156126, 0.0...   \n","31450  [[0.031045783, -0.020515068, 0.0017269664, 0.0...   \n","31451  [[0.0350246, -0.020413548, -0.008156639, 0.023...   \n","\n","                                         text_embeddings  \n","0      [[-0.0073634945, -0.0022322312, -0.0049071913,...  \n","1      [[-0.008894377, -0.00045271497, -0.0051247277,...  \n","2      [[-0.011098293, -0.002307442, -0.0057375436, 0...  \n","3      [[-0.009999439, -0.0022197915, -0.005710659, 0...  \n","4      [[-0.0014464473, -0.0048591304, -0.012673609, ...  \n","...                                                  ...  \n","31447  [[0.050824434, -0.003763202, -0.0049715494, 0....  \n","31448  [[0.04885181, -0.0017174394, -0.0060338983, 0....  \n","31449  [[0.035970498, -0.0088407565, 0.0036507202, 0....  \n","31450  [[0.03335584, -0.00914594, 0.0046747504, 0.013...  \n","31451  [[0.032163326, -0.009161795, 0.0053226887, 0.0...  \n","\n","[31452 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-bd4fce1a-8f6c-4b31-95e9-b4e6d9c365c6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>scientific_name</th>\n","      <th>category</th>\n","      <th>caption</th>\n","      <th>image_embeddings</th>\n","      <th>text_embeddings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>UWZM-F-0001570.JPG                            ...</td>\n","      <td>Lepomis macrochirus</td>\n","      <td>Fish</td>\n","      <td>[This image depicts a Lepomis macrochirus, a s...</td>\n","      <td>[[0.0062551806, 0.016257662, -0.051555164, -0....</td>\n","      <td>[[-0.0073634945, -0.0022322312, -0.0049071913,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>UWZM-F-0001664.JPG                            ...</td>\n","      <td>Lepomis megalotis</td>\n","      <td>Fish</td>\n","      <td>[This image depicts a Lepomis megalotis, showc...</td>\n","      <td>[[-0.010808857, 0.010653244, -0.039921395, 0.0...</td>\n","      <td>[[-0.008894377, -0.00045271497, -0.0051247277,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>UWZM-F-0001696.JPG                            ...</td>\n","      <td>Lepomis microlophus</td>\n","      <td>Fish</td>\n","      <td>[This image depicts a Lepomis microlophus, a s...</td>\n","      <td>[[-0.008302152, 0.016121196, -0.037911564, 0.0...</td>\n","      <td>[[-0.011098293, -0.002307442, -0.0057375436, 0...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>UWZM-F-0001697.JPG                            ...</td>\n","      <td>Lepomis punctatus</td>\n","      <td>Fish</td>\n","      <td>[This image depicts a Lepomis punctatus, a sma...</td>\n","      <td>[[0.005701786, 0.018549936, -0.05157007, 0.001...</td>\n","      <td>[[-0.009999439, -0.0022197915, -0.005710659, 0...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>UWZM-F-0000002.JPG                            ...</td>\n","      <td>Alosa aestivalis</td>\n","      <td>Fish</td>\n","      <td>[The image shows a specimen of Alosa aestivali...</td>\n","      <td>[[-0.008683015, 0.0030286494, -0.040459294, 0....</td>\n","      <td>[[-0.0014464473, -0.0048591304, -0.012673609, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31447</th>\n","      <td>Butterfly_imbalanced_test_Eueides_isabella_114...</td>\n","      <td>Eueides isabella</td>\n","      <td>Butterfly</td>\n","      <td>[The image shows a close-up of Eueides isabell...</td>\n","      <td>[[0.035732385, -0.020132823, -0.017447814, 0.0...</td>\n","      <td>[[0.050824434, -0.003763202, -0.0049715494, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>31448</th>\n","      <td>Butterfly_imbalanced_test_Eueides_isabella_980...</td>\n","      <td>Eueides isabella</td>\n","      <td>Butterfly</td>\n","      <td>[This image shows a close-up of Eueides isabel...</td>\n","      <td>[[0.044416793, -0.034998138, -0.016503036, 0.0...</td>\n","      <td>[[0.04885181, -0.0017174394, -0.0060338983, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>31449</th>\n","      <td>Butterfly_imbalanced_test_Rhetus_periander_307...</td>\n","      <td>Rhetus periander</td>\n","      <td>Butterfly</td>\n","      <td>[The image shows a close-up view of a Rhetus p...</td>\n","      <td>[[0.052031703, -0.01843505, -0.0047156126, 0.0...</td>\n","      <td>[[0.035970498, -0.0088407565, 0.0036507202, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>31450</th>\n","      <td>Butterfly_imbalanced_test_Rhetus_periander_371...</td>\n","      <td>Rhetus periander</td>\n","      <td>Butterfly</td>\n","      <td>[The image shows a close-up of a Rhetus perian...</td>\n","      <td>[[0.031045783, -0.020515068, 0.0017269664, 0.0...</td>\n","      <td>[[0.03335584, -0.00914594, 0.0046747504, 0.013...</td>\n","    </tr>\n","    <tr>\n","      <th>31451</th>\n","      <td>Butterfly_imbalanced_test_Rhetus_periander_372...</td>\n","      <td>Rhetus periander</td>\n","      <td>Butterfly</td>\n","      <td>[The image shows a close-up of Rhetus periande...</td>\n","      <td>[[0.0350246, -0.020413548, -0.008156639, 0.023...</td>\n","      <td>[[0.032163326, -0.009161795, 0.0053226887, 0.0...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31452 rows × 6 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd4fce1a-8f6c-4b31-95e9-b4e6d9c365c6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bd4fce1a-8f6c-4b31-95e9-b4e6d9c365c6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bd4fce1a-8f6c-4b31-95e9-b4e6d9c365c6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-574d4c40-1ea0-4a42-9d03-3a69495669c0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-574d4c40-1ea0-4a42-9d03-3a69495669c0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-574d4c40-1ea0-4a42-9d03-3a69495669c0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_32116dd4-85ac-4579-9b6a-d8e2732907ed\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('embeds_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_32116dd4-85ac-4579-9b6a-d8e2732907ed button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('embeds_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"embeds_df","summary":"{\n  \"name\": \"embeds_df\",\n  \"rows\": 31452,\n  \"fields\": [\n    {\n      \"column\": \"image_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31452,\n        \"samples\": [\n          \"INHS_FISH_77051.jpg                                                                      \",\n          \"Butterfly_imbalanced_test_Eunica_marsolia_36556_CAM044306_d.JPG                          \",\n          \"Common_Yellowthroat_0066_190646.jpg                                                      \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scientific_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 740,\n        \"samples\": [\n          \"Atrosalarias holomelas              \",\n          \"Pomoxis nigromaculatus              \",\n          \"Salarias alboguttatus               \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Fish     \",\n          \"Bird     \",\n          \"Butterfly\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_embeddings\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_embeddings\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# Split in to train/testing"],"metadata":{"id":"4EaXQPUOZoYB"},"id":"4EaXQPUOZoYB"},{"cell_type":"markdown","source":["Training dataset will be used for prototype generation.\n","\n","Testing dataset will be used to evaluate."],"metadata":{"id":"ExJ9YYJ-ZwBu"},"id":"ExJ9YYJ-ZwBu"},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# for this test I'm doing same stratified test_train_split, but I'm making sure count is at LEAST 10 images/class\n","# this will be edited in future iterations, just pushing for now\n","\n","def get_test_train_split(df_cleaned, test_size=0.1):\n","\n","    species_counts = df_cleaned['scientific_name'].value_counts()\n","    valid_species = species_counts[species_counts > 10].index\n","    df_filtered = df_cleaned[df_cleaned['scientific_name'].isin(valid_species)]\n","    calc_min = len(valid_species)/len(df_filtered)\n","    min_split = max(test_size, calc_min)\n","\n","    train_df, test_df = train_test_split(df_filtered, test_size=min_split, stratify=df_filtered['scientific_name'])\n","    return train_df, test_df\n"],"metadata":{"id":"UaIep8m-OJmV"},"id":"UaIep8m-OJmV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# update the test_train_split, stratify + include minimum within train class\n","\n","train_split, test_split = get_test_train_split(embeds_df)"],"metadata":{"id":"7nnqrx8aZKr9","executionInfo":{"status":"ok","timestamp":1732756526040,"user_tz":300,"elapsed":2,"user":{"displayName":"Roman Dombrovski","userId":"00001977524218258424"}}},"id":"7nnqrx8aZKr9","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Create prototypes for each class"],"metadata":{"id":"KKObfxq_atoo"},"id":"KKObfxq_atoo"},{"cell_type":"code","source":["# unique_classes = pd.unique(train_split['scientific_name'])\n","\n","# # create dictionaries to have idx for each unique class\n","# idx_to_class = {idx: cls for idx, cls in enumerate(unique_classes)}\n","# class_to_idx = {cls: idx for idx, cls in enumerate(unique_classes)}\n","\n","train_split[\"embedding_tensor\"] = train_split[\"image_embeddings\"].apply(torch.tensor)\n","class_prototypes = (\n","    train_split.groupby(\"scientific_name\")[\"embedding_tensor\"]\n","    .apply(lambda x: torch.stack(list(x.squeeze(0))).mean(dim=0))\n","    .to_dict()\n",")\n","\n","# create dictionaries to have idx for each unique class\n","prototype_labels = list(class_prototypes.keys())\n","prototype_to_idx = {cls: i for i, cls in enumerate(prototype_labels)}\n","\n","# prototype_to_idx will be used to translate test set from class_name to class_idx"],"metadata":{"id":"LGYM4FyiatCU","executionInfo":{"status":"ok","timestamp":1732758529444,"user_tz":300,"elapsed":1778,"user":{"displayName":"Roman Dombrovski","userId":"00001977524218258424"}}},"id":"LGYM4FyiatCU","execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["# Generate embeddings for images in test set"],"metadata":{"id":"xMYuscnPaxRU"},"id":"xMYuscnPaxRU"},{"cell_type":"code","source":["# this is a test dataset, assuming the embeddings exist on the df\n","\n","class EmbeddingsDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, cls_to_idx, transform=None):\n","        self.df = df\n","        self.transform = transform\n","        self.cls_to_idx = cls_to_idx\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        # Load image and apply transformations\n","        row = self.df.iloc[idx]\n","        image_embeddings = row['image_embeddings']\n","        cls = row['scientific_name']\n","        # image embeddings are size [1, embed_dim] --> squeeze first dim\n","        return image_embeddings.squeeze(0), self.cls_to_idx[cls]\n","\n","dataset = EmbeddingsDataset(test_split, prototype_to_idx)\n","\n","test_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)\n"],"metadata":{"id":"18hhrejUaaLc","executionInfo":{"status":"ok","timestamp":1732758543619,"user_tz":300,"elapsed":288,"user":{"displayName":"Roman Dombrovski","userId":"00001977524218258424"}}},"id":"18hhrejUaaLc","execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["# Calculate Accuracy"],"metadata":{"id":"tJ-I2qE4bFiK"},"id":"tJ-I2qE4bFiK"},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","# remember the embeddings are stored as [1, embed_dim], so need to squeeze\n","\n","def compute_accuracy(test_loader, class_prototypes, prototype_to_idx, topk=(1, 3, 5)):\n","\n","    # assume the prototype embeddings exist in a stack, with the index of the prototype being the same as its class idx\n","    prototype_embeddings = torch.stack(list(class_prototypes.values())).squeeze(1)  # Shape: [num_classes, embedding_dim]\n","\n","    correct = {k: 0 for k in topk}\n","    total = 0\n","\n","    with torch.no_grad():\n","        for embeddings, labels in test_loader:\n","\n","            # Compute similarity between test embeddings and class prototypes\n","\n","            similarities = F.cosine_similarity(embeddings.unsqueeze(1), prototype_embeddings.unsqueeze(0), dim=-1) #  Shape [batch_size, num_classes]\n","\n","            # Get top-k predictions\n","            _, predictions = similarities.topk(max(topk), dim=-1)  # Shape: [batch_size, max(topk)]\n","\n","            # set predictions for each top k (1, 3, 5)\n","            for k in topk:\n","                correct[k] += (predictions[:, :k] == labels.unsqueeze(1)).any(dim=1).sum().item()\n","\n","            total += labels.size(0)\n","\n","    # Compute accuracy for each k\n","    accuracies = {k: correct[k] / total for k in topk}\n","    return accuracies\n","\n","# Run evaluation\n","topk_accuracies = compute_accuracy(test_loader, class_prototypes, prototype_to_idx, topk=(1, 3, 5))\n","print(f\"Top-k Accuracies: {topk_accuracies}\")"],"metadata":{"id":"LNwiDLygaaTw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732758817750,"user_tz":300,"elapsed":6055,"user":{"displayName":"Roman Dombrovski","userId":"00001977524218258424"}},"outputId":"7ad85efa-ca0a-4a86-b315-a648a575d8b3"},"id":"LNwiDLygaaTw","execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Top-k Accuracies: {1: 0.6284135240572172, 3: 0.8403771131339401, 5: 0.9044213263979194}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6IBQZqAyhdpF"},"id":"6IBQZqAyhdpF","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"PyTorch-2.0.1","language":"python","name":"pytorch-2.0.1"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}