{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Colab notebook is made to test classification of Florence-2, Bioclip and Openclip on VLM4Bio datasets. To run this properly, make sure to have a GPU runtime (i.e. T4, L4)."
      ],
      "metadata": {
        "id": "TKPLjj4rbZKB"
      },
      "id": "TKPLjj4rbZKB"
    },
    {
      "cell_type": "code",
      "source": [
        "# required libraries\n",
        "\n",
        "!pip install timm\n",
        "!pip install flash_attn # needs CUDA to run\n",
        "!pip install transformers\n",
        "!pip install open_clip_torch\n",
        "!pip install jsonlines\n",
        "!pip install openai\n",
        "# !pip install datasets # not really necessary but kept for huggingface potential usage\n",
        "# !pip install -q git+https://github.com/roboflow/supervision.git --> fun library if you want to test more vision based stuff with Florence from Roboflow"
      ],
      "metadata": {
        "id": "GGiQYQgjbbTB"
      },
      "id": "GGiQYQgjbbTB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first we grab the image dataset from huggingface. This is the best approach, as the images are analyzed faster on a colab env. This process will take a while (~15min)\n",
        "\n",
        "!git lfs clone https://huggingface.co/datasets/sammarfy/VLM4Bio VLM4BIO_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miM8tfRa6h09",
        "outputId": "90555f09-ffb3-4b6d-fd26-68a05b50845e"
      },
      "id": "miM8tfRa6h09",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
            "          with new flags from 'git clone'\n",
            "\n",
            "'git clone' has been updated in upstream Git to have comparable\n",
            "speeds to 'git lfs clone'.\n",
            "Cloning into 'VLM4BIO_data'...\n",
            "remote: Enumerating objects: 31716, done.\u001b[K\n",
            "remote: Counting objects: 100% (31716/31716), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31648/31648), done.\u001b[K\n",
            "remote: Total 31716 (delta 73), reused 31698 (delta 63), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (31716/31716), 269.44 MiB | 20.00 MiB/s, done.\n",
            "Resolving deltas: 100% (73/73), done.\n",
            "Updating files: 100% (31484/31484), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we move the VLM4Bio datasets from the folder.. rest of info is unnecessary\n",
        "\n",
        "!mv VLM4BIO_data/datasets .\n",
        "!rm -R VLM4BIO_data"
      ],
      "metadata": {
        "id": "Z9HVpmY_B2he"
      },
      "id": "Z9HVpmY_B2he",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to colab to get the scripts from drive (TODO: instead of doing it this way, can git clone from biocosmos?)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfWZFnl0BwyU",
        "outputId": "872c2f2f-7bd8-4dbf-f5cc-4b3ebb1c9238"
      },
      "id": "lfWZFnl0BwyU",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I'm grabbing the necessary scripts path from my drive and putting it on the colab instance\n",
        "\n",
        "# keep in mind, this is the path where I keep MY scripts, it will be different for you\n",
        "!cp -r drive/MyDrive/OMSCS/my_VLM4Bio VLM4Bio\n",
        "!mv datasets VLM4Bio/\n",
        "\n",
        "!mkdir VLM4Bio/datasets/Fish/images\n",
        "!mkdir VLM4Bio/datasets/Bird/images\n",
        "!mkdir VLM4Bio/datasets/Butterfly/images\n",
        "!cp VLM4Bio/datasets/Fish/chunk_*/** VLM4Bio/datasets/Fish/images/\n",
        "!cp VLM4Bio/datasets/Bird/chunk_*/** VLM4Bio/datasets/Bird/images/\n",
        "!cp VLM4Bio/datasets/Butterfly/chunk_*/** VLM4Bio/datasets/Butterfly/images/"
      ],
      "metadata": {
        "id": "9YPD1NV1C2Jb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344b2bdb-56b0-4472-8ffa-030fb8b6c140"
      },
      "id": "9YPD1NV1C2Jb",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'datasets': No such file or directory\n",
            "mkdir: cannot create directory ‘VLM4Bio/datasets/Fish/images’: File exists\n",
            "mkdir: cannot create directory ‘VLM4Bio/datasets/Bird/images’: File exists\n",
            "mkdir: cannot create directory ‘VLM4Bio/datasets/Butterfly/images’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell will be used to run the vlm4_bio classification test. Models that are currently tested are: Bioclip, Openclip and Florence-2.\n",
        "\n",
        "By default, the model will be openclip.\n",
        "\n",
        "Rest of the settings for the script:\n",
        "\n",
        "```\n",
        "parser.add_argument(\"--model\", \"-m\", type=str, default='florence', help=\"\")\n",
        "parser.add_argument(\"--task_option\", \"-t\", type=str, default='direct', help=\"task option: 'direct', 'selection' \")\n",
        "parser.add_argument(\"--result_dir\", \"-r\", type=str, default='./results/', help=\"path to output\")\n",
        "parser.add_argument(\"--data_dir\", \"-o\", type=str, default='data/', help=\"path to datasets\")\n",
        "parser.add_argument(\"--num_queries\", \"-n\", type=int, default=-1, help=\"number of images to query from dataset\")\n",
        "parser.add_argument(\"--chunk_id\", \"-c\", type=int, default=0, help=\"0, 1, 2, 3, 4, 5, 6, 7, 8, 9\")\n",
        "parser.add_argument(\"--dataset\", \"-d\", type=str, default='fish', help=\"dataset option: 'fish', 'bird', 'butterfly' \")\n",
        "```\n",
        "\n",
        "Example run:\n",
        "`!python VLM4Bio/vlm4bio_classification.py -o '' -m 'florence-2'`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d6Q8xXvyiAUJ"
      },
      "id": "d6Q8xXvyiAUJ"
    },
    {
      "cell_type": "code",
      "source": [
        " !python VLM4Bio/vlm4bio_classification.py -o '' -m 'florence-2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJG29i8OE74a",
        "outputId": "2b235234-f826-45a7-f651-3141bcd3e419"
      },
      "id": "TJG29i8OE74a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-15 21:12:48.596891: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-15 21:12:48.618372: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-15 21:12:48.624673: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-15 21:12:48.639710: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-15 21:12:49.949726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Arguments Provided:  Namespace(model='florence-2', task_option='direct', result_dir='results/fish/classification/direct', data_dir='', num_queries=-1, chunk_id=0, dataset='fish')\n",
            "writing to  results/fish/classification/direct/classification_florence-2_direct_num_1034_chunk_0.jsonl\n",
            "config.json: 100% 2.43k/2.43k [00:00<00:00, 17.5MB/s]\n",
            "configuration_florence2.py: 100% 15.1k/15.1k [00:00<00:00, 49.2MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-base:\n",
            "- configuration_florence2.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_florence2.py: 100% 127k/127k [00:00<00:00, 53.7MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-base:\n",
            "- modeling_florence2.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "pytorch_model.bin: 100% 464M/464M [00:01<00:00, 337MB/s]\n",
            "preprocessor_config.json: 100% 806/806 [00:00<00:00, 4.46MB/s]\n",
            "processing_florence2.py: 100% 46.4k/46.4k [00:00<00:00, 142MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-base:\n",
            "- processing_florence2.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "tokenizer_config.json: 100% 34.0/34.0 [00:00<00:00, 228kB/s]\n",
            "vocab.json: 100% 1.10M/1.10M [00:00<00:00, 4.97MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 5.90MB/s]\n",
            " 14% 18/130 [00:56<06:41,  3.58s/it]This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
            " 34% 44/130 [03:40<04:22,  3.05s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JBU4QR0Nis2c"
      },
      "id": "JBU4QR0Nis2c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}